{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING DATA SET\n",
    "\n",
    "data = pd.read_csv(\"RealDataSet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 : Replacing shortcuts.\n",
    "\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace(['LF'],'Low Fat')\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace(['reg'],'Regular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before filling missing values.\n",
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 : Filling missing values.\n",
    "#Now filling the null values.\n",
    "def imputing_numeric_missing_values(dataset,n_neighbors=10):\n",
    "    numerical_column_names = dataset.select_dtypes([np.number]).columns\n",
    "    knn= KNNImputer()\n",
    "    knn_dataset= knn.fit_transform(dataset[numerical_column_names])\n",
    "    \n",
    "    dataset[numerical_column_names]=pd.DataFrame(knn_dataset)\n",
    "    return dataset\n",
    "\n",
    "dataset=imputing_numeric_missing_values(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding missing values\n",
    "dist = data.Outlet_Size.value_counts(normalize=True)\n",
    "nan_outlet_rows = data['Outlet_Size'].isnull()\n",
    "data.loc[nan_outlet_rows,'Outlet_Size'] = np.random.choice(dist.index, size=len(data[nan_outlet_rows]),p=dist.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After filling out missing values\n",
    "#data.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting string values to numeric values.\n",
    "# we have to convert following.\n",
    "# here we convert the string based columns into integer or in numeric form.\n",
    "#Converting to feature name\n",
    "ord_enc = OrdinalEncoder()\n",
    "enc = LabelEncoder()   \n",
    "\n",
    "enc.fit(data['Item_Type']) \n",
    "data[\"Item_Type\"] = ord_enc.fit_transform(data[[\"Item_Type\"]])\n",
    "\n",
    "enc.fit(data['Outlet_Type']) \n",
    "data[\"Outlet_Type\"] = ord_enc.fit_transform(data[[\"Outlet_Type\"]])\n",
    "\n",
    "enc.fit(data['Outlet_Location_Type']) \n",
    "data[\"Outlet_Location_Type\"] = ord_enc.fit_transform(data[[\"Outlet_Location_Type\"]])\n",
    "\n",
    "enc.fit(data['Outlet_Size']) \n",
    "data[\"Outlet_Size\"] = ord_enc.fit_transform(data[[\"Outlet_Size\"]])\n",
    "\n",
    "\n",
    "# we have columns named : Item_Fat_Content to be just binarize\n",
    "diag_map = {'Low Fat':1, 'Regular':0}\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].map(diag_map)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After convergion of string values to numeric form ... Ordinal -> numeric conversion\n",
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now standarizing some specific columns.\n",
    "#Since we have decided to keep Outlet_Type \n",
    "#for classification purposed. So except this \n",
    "#and columns which are showing labels or behaving like\n",
    "#categorical data we will not convert them.\n",
    "\n",
    "data[['Item_Weight', 'Item_Visibility','Item_MRP']] = StandardScaler().fit_transform(data[['Item_Weight', 'Item_Visibility','Item_MRP'] ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5681 entries, 0 to 5680\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Item_Identifier            5681 non-null   object \n",
      " 1   Item_Weight                5681 non-null   float64\n",
      " 2   Item_Fat_Content           5615 non-null   float64\n",
      " 3   Item_Visibility            5681 non-null   float64\n",
      " 4   Item_Type                  5681 non-null   float64\n",
      " 5   Item_MRP                   5681 non-null   float64\n",
      " 6   Outlet_Identifier          5681 non-null   object \n",
      " 7   Outlet_Establishment_Year  5681 non-null   float64\n",
      " 8   Outlet_Size                5681 non-null   float64\n",
      " 9   Outlet_Location_Type       5681 non-null   float64\n",
      " 10  Outlet_Type                5681 non-null   float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 488.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Columns before making selection.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now making selection of features.\n",
    "# We will drop two columns which are just showing the IDs.\n",
    "to_drop = ['Item_Identifier','Outlet_Identifier']\n",
    "data.drop(to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And for rest of selection we will data the co-relation graph.\n",
    "# Now ploting the graph\n",
    "def draw_heatmap(dataset):\n",
    "    \n",
    "    \n",
    "    f, ax = plt.subplots(figsize = (18, 18))\n",
    "    \n",
    "    corrMatt = dataset.corr(method='spearman')\n",
    "    \n",
    "    sns.heatmap(corrMatt, annot = True, linewidth = 0.5, fmt = '.1f', ax = ax)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    \n",
    "numerical_df_1=data.select_dtypes(numerics)\n",
    "numerical_column_names = data.select_dtypes(numerics).columns\n",
    "\n",
    "#draw_heatmap(numerical_df_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
